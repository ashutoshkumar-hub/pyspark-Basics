{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa1ce86-f7dc-4e6d-a94a-eeb00ded45e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+-------+\n| id|  name|gender|salary| depart|\n+---+------+------+------+-------+\n|  1|  Ashu|  male| 20000|     IT|\n|  2|Swetha|female| 40000|     HR|\n|  3|   Asi|female| 50000|     IT|\n|  4| Atlee|  male|  6000|Payroll|\n+---+------+------+------+-------+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- depart: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'Ashu','male',20000,'IT'),(2,'Swetha','female',40000,'HR'),(3,'Asi','female',50000,'IT'),(4,'Atlee','male',6000,'Payroll')]\n",
    "\n",
    "schema=['id','name','gender','salary','depart']\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26008173-8af4-488d-9a0f-79f110c522f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+-------+\n| id|  name|gender|salary| depart|\n+---+------+------+------+-------+\n|  2|Swetha|female| 40000|     HR|\n|  3|   Asi|female| 50000|     IT|\n|  1|  Ashu|  male| 20000|     IT|\n|  4| Atlee|  male|  6000|Payroll|\n+---+------+------+------+-------+\n\n+---+------+------+------+-------+\n| id|  name|gender|salary| depart|\n+---+------+------+------+-------+\n|  2|Swetha|female| 40000|     HR|\n|  3|   Asi|female| 50000|     IT|\n|  1|  Ashu|  male| 20000|     IT|\n|  4| Atlee|  male|  6000|Payroll|\n+---+------+------+------+-------+\n\n+---+------+------+------+-------+\n| id|  name|gender|salary| depart|\n+---+------+------+------+-------+\n|  2|Swetha|female| 40000|     HR|\n|  3|   Asi|female| 50000|     IT|\n|  1|  Ashu|  male| 20000|     IT|\n|  4| Atlee|  male|  6000|Payroll|\n+---+------+------+------+-------+\n\n+---+------+------+------+-------+\n| id|  name|gender|salary| depart|\n+---+------+------+------+-------+\n|  2|Swetha|female| 40000|     HR|\n|  1|  Ashu|  male| 20000|     IT|\n|  3|   Asi|female| 50000|     IT|\n|  4| Atlee|  male|  6000|Payroll|\n+---+------+------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df.sort('depart').show() #method 1\n",
    "df.sort(df.depart).show() #method 2\n",
    "df.sort(df.depart,df.id.desc()).show()\n",
    "\n",
    "df.orderBy(df.depart.asc(),df.id.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce45ab70-91ff-4095-be2e-9fc48c2b0f0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "orderByNotebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
