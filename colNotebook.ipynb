{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a23c94-e7ca-4fda-994c-73a2a861d2d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "col1 = lit('abcd') # lit functions which is create one column\n",
    "print(type(col1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1d9d64-c209-4d68-b3b6-6eb55d7160ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n|  name|gender|salary|\n+------+------+------+\n|  Ashu|  male| 20000|\n|Swetha|female| 40000|\n+------+------+------+\n\nroot\n |-- name: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "data = [('Ashu','male',20000),('Swetha','female', 40000)]\n",
    "\n",
    "schema=['name','gender','salary']\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33a9c6c-3522-4a83-a234-7819adcb50f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+--------+\n|  name|gender|salary|  newCol|\n+------+------+------+--------+\n|  Ashu|  male| 20000|newValue|\n|Swetha|female| 40000|newValue|\n+------+------+------+--------+\n\nroot\n |-- name: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- newCol: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('newCol',lit('newValue'))\n",
    "\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679237e1-6e67-4fff-9d80-84eb894e610e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|  name|\n+------+\n|  Ashu|\n|Swetha|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "df1.select(df['name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407d7ea6-892a-4c3a-a501-06af59299439",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|  name|\n+------+\n|  Ashu|\n|Swetha|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df1.select(col('name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec010388-fe68-407a-a705-d5fac953c76c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+--------------+\n|  name|gender|salary|         props|\n+------+------+------+--------------+\n|  Ashu|  male| 20000|{brown, black}|\n|Swetha|female| 40000| {blue, black}|\n+------+------+------+--------------+\n\nroot\n |-- name: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- props: struct (nullable = true)\n |    |-- hair: string (nullable = true)\n |    |-- eye: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType,StructType,StructField,IntegerType\n",
    "\n",
    "data = [('Ashu','male',20000,('brown','black')),('Swetha','female', 40000,('blue','black'))]\n",
    "\n",
    "propsType = StructType([\n",
    "    StructField('hair',StringType()),\\\n",
    "    StructField('eye',StringType())\n",
    "])\n",
    "\n",
    "schema=StructType([\n",
    "    StructField('name',StringType()),\\\n",
    "    StructField('gender',StringType()),\\\n",
    "    StructField('salary',IntegerType()),\\\n",
    "    StructField('props',propsType)    \n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data,schema)\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c18bbe-b505-42e7-9ba3-c0f9a935630b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|props.eye|\n+---------+\n|    black|\n|    black|\n+---------+\n\n+-----+\n|  eye|\n+-----+\n|black|\n|black|\n+-----+\n\n+-----+\n|  eye|\n+-----+\n|black|\n|black|\n+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(df.props.eye).show()\n",
    "df.select(df['props.eye']).show()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col('props.eye')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b219311-98b0-4831-85ce-1a78264c2f86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "colNotebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
